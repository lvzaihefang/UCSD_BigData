{
 "metadata": {
  "name": "",
  "signature": "sha256:a260412b37a9257aae4c24f72c387331d67e86050ab72ea06fb0fda886ce7ea6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this assignment you are asked to analyze the complete weather dataset.\n",
      "\n",
      "\n",
      "### Possible directions, from the general to the specific ###\n",
      "The following questions are meant as starting points, you are encouraged to go beyond them.\n",
      "Remember to describe your work, with words and figures, so that your reviewers, and anybody else, would be able to follow."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Coverage and Cleanup ###\n",
      "While the weather data collection is large, its coverage is very uneven. Many active stations exist in the USA and in India, while there are relatively very few in Africa.\n",
      "\n",
      "In this section our goal is to characterize the coverage of the data and to clean it based on the coverage.\n",
      "By *coverage* we mean to identify the geographic locations, times and types of measurements for which we have a lot of data and\n",
      "the parts for which we have only little. By establishing the coverage we identify the types of statistical queries that we can make and the types for which we have too little data.\n",
      "\n",
      "**Heirarchical representation:** When we want to represent sparse data, it is often useful to create a hierarchy:\n",
      "\n",
      "1. **Can we ignore stations with no temperature recordings?** It seems reasonable to assume that any station that has published useful measurements has at least published minimum and maximum termperatures. Can you confirm or deny this?\n",
      "1. **Geographic baseline:** Some parts of the world have a lot of stations and measurements, some very few. Create a hierarchical representation of this data. \n",
      "1. **Measurement Types ** There is a large number of measurements, but most of them occur only rarely. Can you compute and describe:\n",
      "  1. How many times does each type of measurement occur in the database.\n",
      "  1. What fraction of the entries are not empty?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import sklearn as sk\n",
      "print 'pandas version: ',pd.__version__\n",
      "print 'numpy version:',np.__version__\n",
      "print 'sklearn version:',sk.__version__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "pandas version:  0.13.1\n",
        "numpy version: 1.8.1\n",
        "sklearn version: 0.14.1\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys,os\n",
      "cwd=os.getcwd()\n",
      "path=cwd.split('/')\n",
      "home_dir='/'.join(path[:-2])\n",
      "print home_dir\n",
      "sys.path.append(home_dir+'/utils')\n",
      "from find_waiting_flow import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/ubuntu/UCSD_BigData\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Question 1 : Can we ignore stations with no temperature recordings? ###"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since there are five core elements in all the measurements:\n",
      "\n",
      "       PRCP = Precipitation (tenths of mm)\n",
      "   \t   SNOW = Snowfall (mm)\n",
      "\t   SNWD = Snow depth (mm)\n",
      "       TMAX = Maximum temperature (tenths of degrees C)\n",
      "       TMIN = Minimum temperature (tenths of degrees C)\n",
      "\n",
      "To answer this question, we consider that if a station satisfies that (1) if it has TMAX and TMIN, there is high probability that it has most of all the other three core elements (2) if it doesn't have both TMAX and TMIN, there is high probability that it doesn't have much of the other three core elements.\n",
      "Therefore, I divide all stations into two types, Type A and Type B. Type A has both TMAX and TMIN. Type B has at most has one of TMAX and TMIN. \n",
      "Type A can be further divided into 4 types: \n",
      "    A.0 has 0 other three core elements.\n",
      "    A.1 has 1 other three core elements.\n",
      "    A.2 has 2 other three core elements.\n",
      "    A.3 has 3 other three core elements.\n",
      "Type B can be further divided into 4 types: \n",
      "    B.0 has 0 other three core elements.\n",
      "    B.1 has 1 other three core elements.\n",
      "    B.2 has 2 other three core elements.\n",
      "    B.3 has 3 other three core elements.\n",
      "\n",
      "The following procedure uses mapreduce to calculate the number of data in each types."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile Stations_Statistics.py\n",
      "#!/usr/bin/python\n",
      "\"\"\"\n",
      "collect the statistics for each station.\n",
      "\"\"\"\n",
      "from ECatch import *\n",
      "import re,pickle,base64,zlib\n",
      "from sys import stderr\n",
      "import sys\n",
      "\n",
      "sys.path.append('/usr/lib/python2.6/dist-packages') # a hack because anaconda made mrjob unreachable\n",
      "from mrjob.job import MRJob\n",
      "from mrjob.protocol import *\n",
      "\n",
      "import traceback\n",
      "from functools import wraps\n",
      "from sys import stderr\n",
      "\n",
      "\"\"\"this decorator is intended for decorating a function, not a\n",
      "generator.  Therefor to use it in the context of mrjob, the generator\n",
      "should call a function that handles a single input records, and that\n",
      "function should be decorated.\n",
      "\n",
      "The reason is that if a generator throws an exception it exits and\n",
      "cannot process any more records.\n",
      "\n",
      "\"\"\"\n",
      "def ECatch(func):\n",
      "    f_name=func.__name__\n",
      "    @wraps(func)\n",
      "    def inner(self,*args,**kwargs):\n",
      "        try:\n",
      "            self.increment_counter(self.__class__.__name__,'total in '+f_name,1)\n",
      "            return func(self,*args,**kwargs)\n",
      "        except Exception as e:\n",
      "            self.increment_counter(self.__class__.__name__,'errors in '+f_name,1)\n",
      "            stderr.write('Error:')\n",
      "            stderr.write(str(e))\n",
      "            traceback.print_exc(file=stderr)\n",
      "            stderr.write('Arguments were %s, %s\\n'%(args,kwargs))\n",
      "            pass\n",
      "    return inner\n",
      "\n",
      "class MRWeather(MRJob):\n",
      "\n",
      "    @ECatch\n",
      "    def map_one(self,line):\n",
      "        return line.split(',')\n",
      "    \n",
      "    def mapper(self, _, line):\n",
      "        elements=self.map_one(line)\n",
      "        # key: station  value: measurement\n",
      "        yield (elements[0],elements[2]), elements[1]\n",
      "    \n",
      "    def get_category(self, lst):\n",
      "        var hasTMAX = 0\n",
      "        var hasTMIN = 0\n",
      "        for ele in lst:\n",
      "            if ele == \"TMAX\":\n",
      "                hasTMAX = 1\n",
      "            else if ele == \"TMIN\":\n",
      "                hasTMIN = 1\n",
      "        # The station has TMAX and TMIN data\n",
      "        if hasTMAX + hasTMIN == 2:\n",
      "            return len(lst) - 2\n",
      "        if hasTMAX + hasTMIN == 1:\n",
      "            return 3 + len(lst) - 1\n",
      "        return 3 + len(lst)\n",
      "    \n",
      "    @ECatch\n",
      "    def reducer(self, key, vals):\n",
      "        counter = [0,0,0,0,0,0,0,0]\n",
      "        cat = self.get_category(vals)\n",
      "        yield(station,sum(vals))\n",
      "                              \n",
      "if __name__ == '__main__':\n",
      "    MRWeather.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing Stations_Statistics.py\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "Creds_file='/home/ubuntu/Vault/Creds.pkl'\n",
      "Creds= pickle.load(open(Creds_file,'rb'))\n",
      "print Creds.keys()\n",
      "print Creds['mrjob'].keys()\n",
      "pair=Creds['mrjob']\n",
      "key_id=pair['key_id']\n",
      "secret_key=pair['secret_key']\n",
      "ID=pair['ID']\n",
      "print ID,key_id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['launcher', 'mrjob']\n",
        "['key_id', 'secret_key', 's3_logs', 'ID', 's3_scratch']\n",
        "r4he AKIAISHBCJLKEX3YBOWA\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "job_flow_id=find_waiting_flow(key_id,secret_key)\n",
      "job_flow_id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<boto.emr.emrobject.JobFlow object at 0x4447950> no_script.yoavfreund.20140517.080731.371759 j-1RE8D7HBISOI0 WAITING\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "u'j-1RE8D7HBISOI0'"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python Stations_Statistics.py -r emr --emr-job-flow-id $job_flow_id $data_dir/ALL.corrupted.csv > StationStatistics.pkl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat DataCellNumForEachStation.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}